{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d749a561-c8fc-4991-afe9-7113d3c6017c",
   "metadata": {},
   "source": [
    "### Trying out RAG with ollama and chromadb\n",
    "ollama is installed in the python environment venvcrc5 from where this notebook is started.\n",
    "\n",
    "ollama is recommended over hugging face for local experimentation\n",
    "\n",
    "it uses a docker-like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de73eae-777f-4b14-9ed4-cbdd2cfd4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  ollama [flags]\n",
      "  ollama [command]\n",
      "\n",
      "Available Commands:\n",
      "  serve       Start ollama\n",
      "  create      Create a model from a Modelfile\n",
      "  show        Show information for a model\n",
      "  run         Run a model\n",
      "  stop        Stop a running model\n",
      "  pull        Pull a model from a registry\n",
      "  push        Push a model to a registry\n",
      "  list        List models\n",
      "  ps          List running models\n",
      "  cp          Copy a model\n",
      "  rm          Remove a model\n",
      "  help        Help about any command\n",
      "\n",
      "Flags:\n",
      "  -h, --help      help for ollama\n",
      "  -v, --version   Show version information\n",
      "\n",
      "Use \"ollama [command] --help\" for more information about a command.\n",
      "ollama version is 0.5.7\n",
      "NAME                       ID              SIZE      MODIFIED     \n",
      "deepseek-r1:14b            ea35dfe18182    9.0 GB    4 weeks ago     \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    4 weeks ago     \n",
      "gemma3:12b                 6fd036cefda5    8.1 GB    2 months ago    \n",
      "deepseek-r1:7b             0a8c26691023    4.7 GB    2 months ago    \n",
      "deepseek-r1:1.5b           a42b25d8c10a    1.1 GB    2 months ago    \n",
      "deepseek-r1:latest         0a8c26691023    4.7 GB    3 months ago    \n",
      "llama3.1:latest            46e0c10c039e    4.9 GB    3 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama\n",
    "!ollama --version\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d32e73-ede0-4a86-b35a-7fa55ebf7cfb",
   "metadata": {},
   "source": [
    "#### The pdfreader translates any pdf document to text readable by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59742336-ba28-4ad4-ad9f-b483638d3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "# my textbook, 5th ed\n",
    "reader = PdfReader(\"/home/mort/LaTeX/new projects/CRC5/main.pdf\")\n",
    "total_pages = len(reader.pages)\n",
    "all_text = \"\"\n",
    "for page_num in range(total_pages):\n",
    "    page = reader.pages[page_num]\n",
    "    all_text += page.extract_text()\n",
    "f = open(\"/home/mort/crc5pdfreader/main.txt\", \"w\")\n",
    "f.write(all_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a22089-22a2-4f18-aa53-8c8bc911f7f0",
   "metadata": {},
   "source": [
    "#### Here the original LaTeX files are collected instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7d2e14-d5c0-4b02-8151-7a63f0031b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# Find `.tex` files in LaTeX directory and all subdirectories\n",
    "tex_files = glob.glob('/home/mort/LaTeX/new projects/CRC5/**/chapter[1-9].tex', recursive = True)\n",
    "tex_files.sort()\n",
    "f = open(\"/home/mort/crc5latex/main.txt\", \"w\")\n",
    "for file in tex_files:\n",
    "    g = open(file, \"r\")\n",
    "    content = g.read()\n",
    "    f.write(content)\n",
    "    g.close()\n",
    "f.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ef2f9-2ced-4769-a465-0948676ee37f",
   "metadata": {},
   "source": [
    "#### The LlamaParse version of the text pdf (parsed from the web API) is stored in /home/mort/crc5llamaparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ac292-fa28-4fcb-a5dd-002b50a4fc6e",
   "metadata": {},
   "source": [
    "#### Code for preprocessing the RAG supplementary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ad0df7-ee8e-46e9-b238-2399293e17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def readtextfiles(path):\n",
    "    text_contents = {}\n",
    "    directory = os.path.join(path)\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "        \n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "        \n",
    "            text_contents[filename] = content\n",
    "        \n",
    "        return text_contents\n",
    "\n",
    "def chunksplitter(text, chunk_size=512, chunk_overlap=128):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,  # Desired chunk size in tokens\n",
    "        chunk_overlap=chunk_overlap,  # Overlap between chunks\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Split by paragraphs, then sentences, then words\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# use the nomic-embed-text model to calculate vector embeddings for all text chunks\n",
    "def getembedding(chunks):\n",
    "    embeds = ollama.embed(model=\"nomic-embed-text\", input=chunks)\n",
    "    return embeds.get('embeddings', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f159d-9e67-4f56-af9a-2627d26f042b",
   "metadata": {},
   "source": [
    "#### Add the supplementary text to a new database collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c45bcb2-4e75-413c-83ca-2c36046d094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "#chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5imagery/crc5rag\")\n",
    "chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5rag\")\n",
    "chromaclient.delete_collection(\"crc5rag\")\n",
    "collection = chromaclient.create_collection(name=\"crc5rag\", metadata={\"hnsw:space\": \"cosine\"}  )\n",
    "\n",
    "# the RAG supplementary data, here using the llamaparse version of the main pdf\n",
    "textdocspath = \"/home/mort/crc5llamaparse\"\n",
    "text_data = readtextfiles(textdocspath)\n",
    "\n",
    "# read, break into chunks, embed and add to the chroma vector database \n",
    "for filename, text in text_data.items():\n",
    "    # chunk size set to 512, overlap 128 (defaults)\n",
    "    chunks = chunksplitter(text)\n",
    "    embeds = getembedding(chunks)\n",
    "    chunknumber = list(range(len(chunks)))\n",
    "    ids = [filename + str(index) for index in chunknumber]\n",
    "    metadatas = [{\"source\": filename} for index in chunknumber]\n",
    "    collection.add(ids=ids, documents=chunks, embeddings=embeds, metadatas=metadatas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9451e-7588-4db5-a87a-d96ee9a152b5",
   "metadata": {},
   "source": [
    "#### Execute a query with llama3.1 or deepseek-r1 and the supplementary text (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66a69bd-b4a6-4c28-91fc-f4b0ff5a1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ollama pull nomic-embed-text\n",
    "#!ollama pull llama3.1\n",
    "!ollama pull deepseek-r1:14b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807bd52a-fa9b-435e-80a0-95c6c5560909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import html\n",
    "import ollama\n",
    "import chromadb\n",
    "\n",
    "# Initialize ChromaDB client and collection\n",
    "#chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5imagery/crc5rag\")\n",
    "chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5rag\")\n",
    "collection = chromaclient.get_collection(name=\"crc5rag\")\n",
    "\n",
    "def ragask(query):\n",
    "    # Embed the query\n",
    "    queryembed = ollama.embed(model=\"nomic-embed-text\", input=query)['embeddings']\n",
    "    # Retrieve related documents\n",
    "    relateddocs = '\\n\\n'.join(collection.query(query_embeddings=queryembed, n_results=8)['documents'][0])\n",
    "    # Generate a response\n",
    "    prompt = f\"Answer the question: {query} referring to the following text as a resource: {relateddocs}\"\n",
    "    response = ollama.generate(model=\"deepseek-r1:14b\", prompt=prompt, stream=False)['response']   \n",
    "    # Ensure the response is valid Markdown\n",
    "    return html.escape(response)\n",
    "\n",
    "# Launch Gradio Interface (ChatInterface not appropriate for RAG application!)\n",
    "gr.Interface(fn=ragask,inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
    "             outputs=\"markdown\",\n",
    "             description=\"Ask questions about the book contents\",\n",
    "             title=\"Image Analysis, Classification and Change Detection in Remote Sensing\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155124d-17bd-47dd-85cb-7ff45a7b54b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
