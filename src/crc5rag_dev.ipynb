{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d749a561-c8fc-4991-afe9-7113d3c6017c",
   "metadata": {},
   "source": [
    "### Trying out RAG with ollama and chromadb\n",
    "ollama is installed in the python environment venvcrc5 from where this notebook is started.\n",
    "\n",
    "ollama is recommended over hugging face for local experimentation\n",
    "\n",
    "it uses a docker-like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae078fb-9412-4764-be71-68e9114e69ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1G⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[K\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25hYou need to be signed in to Ollama to run Cloud models.\n",
      "\n",
      "To sign in, navigate to:\n",
      "    https://ollama.com/connect?name=nuc11&key=c3NoLWVkMjU1MTkgQUFBQUMzTnphQzFsWkRJMU5URTVBQUFBSUtRSUZNMHZoS1RtNEpmS2hiWXVodjVuMmcyKytIS0NxcktHL3VlSmNpY3k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ollama run deepseek-v3.1:671b-cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d10880-94b2-45b3-b95c-3d1675dd5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        ID              SIZE      MODIFIED     \n",
      "deepseek-r1:14b             c333b7232bdb    9.0 GB    19 hours ago    \n",
      "nomic-embed-text:latest     0a109f422b47    274 MB    19 hours ago    \n",
      "deepseek-v3.1:671b-cloud    d3749919e45f    -         25 hours ago    \n",
      "deepseek-r1:1.5b            e0979632db5a    1.1 GB    8 weeks ago     \n",
      "deepseek-r1:7b              755ced02ce7b    4.7 GB    8 weeks ago     \n",
      "gemma3:12b                  6fd036cefda5    8.1 GB    6 months ago    \n",
      "deepseek-r1:latest          0a8c26691023    4.7 GB    7 months ago    \n",
      "llama3.1:latest             46e0c10c039e    4.9 GB    7 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de73eae-777f-4b14-9ed4-cbdd2cfd4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  ollama [flags]\n",
      "  ollama [command]\n",
      "\n",
      "Available Commands:\n",
      "  serve       Start ollama\n",
      "  create      Create a model\n",
      "  show        Show information for a model\n",
      "  run         Run a model\n",
      "  stop        Stop a running model\n",
      "  pull        Pull a model from a registry\n",
      "  push        Push a model to a registry\n",
      "  signin      Sign in to ollama.com\n",
      "  signout     Sign out from ollama.com\n",
      "  list        List models\n",
      "  ps          List running models\n",
      "  cp          Copy a model\n",
      "  rm          Remove a model\n",
      "  help        Help about any command\n",
      "\n",
      "Flags:\n",
      "  -h, --help      help for ollama\n",
      "  -v, --version   Show version information\n",
      "\n",
      "Use \"ollama [command] --help\" for more information about a command.\n",
      "ollama version is 0.12.0\n",
      "NAME                        ID              SIZE      MODIFIED     \n",
      "deepseek-r1:14b             c333b7232bdb    9.0 GB    19 hours ago    \n",
      "nomic-embed-text:latest     0a109f422b47    274 MB    19 hours ago    \n",
      "deepseek-v3.1:671b-cloud    d3749919e45f    -         25 hours ago    \n",
      "deepseek-r1:1.5b            e0979632db5a    1.1 GB    8 weeks ago     \n",
      "deepseek-r1:7b              755ced02ce7b    4.7 GB    8 weeks ago     \n",
      "gemma3:12b                  6fd036cefda5    8.1 GB    6 months ago    \n",
      "deepseek-r1:latest          0a8c26691023    4.7 GB    7 months ago    \n",
      "llama3.1:latest             46e0c10c039e    4.9 GB    7 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama\n",
    "!ollama --version\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289f0622-759b-4071-bb1e-e83d8cffb282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pull a model from a registry\n",
      "\n",
      "Usage:\n",
      "  ollama pull MODEL [flags]\n",
      "\n",
      "Flags:\n",
      "  -h, --help       help for pull\n",
      "      --insecure   Use an insecure registry\n",
      "\n",
      "Environment Variables:\n",
      "      OLLAMA_HOST                IP Address for the ollama server (default 127.0.0.1:11434)\n"
     ]
    }
   ],
   "source": [
    "!ollama help pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e250d6-50a1-430f-aaa8-526ef021bcf8",
   "metadata": {},
   "source": [
    "#### Pull the cloud-hosted deepseek-v3.1:671b-cloud model (experimental, not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aeb2cee-a8a9-4d8b-bb09-5dc46a79d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 8aacb627728e: 100% ▕██████████████████▏  405 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-v3.1:671b-cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05748c0b-3c8d-4cbf-a2df-74183f04c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        ID              SIZE      MODIFIED       \n",
      "deepseek-r1:14b             c333b7232bdb    9.0 GB    12 minutes ago    \n",
      "nomic-embed-text:latest     0a109f422b47    274 MB    12 minutes ago    \n",
      "deepseek-v3.1:671b-cloud    d3749919e45f    -         6 days ago        \n",
      "deepseek-r1:1.5b            e0979632db5a    1.1 GB    2 months ago      \n",
      "deepseek-r1:7b              755ced02ce7b    4.7 GB    2 months ago      \n",
      "gemma3:12b                  6fd036cefda5    8.1 GB    6 months ago      \n",
      "deepseek-r1:latest          0a8c26691023    4.7 GB    7 months ago      \n",
      "llama3.1:latest             46e0c10c039e    4.9 GB    7 months ago      \n"
     ]
    }
   ],
   "source": [
    "!ollama ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d32e73-ede0-4a86-b35a-7fa55ebf7cfb",
   "metadata": {},
   "source": [
    "#### The pdfreader translates any pdf document to text readable by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59742336-ba28-4ad4-ad9f-b483638d3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "# my textbook, 5th ed\n",
    "reader = PdfReader(\"/home/mort/LaTeX/new projects/CRC5/main.pdf\")\n",
    "total_pages = len(reader.pages)\n",
    "all_text = \"\"\n",
    "for page_num in range(total_pages):\n",
    "    page = reader.pages[page_num]\n",
    "    all_text += page.extract_text()\n",
    "f = open(\"/home/mort/crc5pdfreader/main.txt\", \"w\")\n",
    "f.write(all_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a22089-22a2-4f18-aa53-8c8bc911f7f0",
   "metadata": {},
   "source": [
    "#### Here the original LaTeX files are collected instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7d2e14-d5c0-4b02-8151-7a63f0031b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# Find `.tex` files in LaTeX directory and all subdirectories\n",
    "tex_files = glob.glob('/home/mort/LaTeX/new projects/CRC5/**/chapter[1-9].tex', recursive = True)\n",
    "tex_files.sort()\n",
    "f = open(\"/home/mort/crc5latex/main.txt\", \"w\")\n",
    "for file in tex_files:\n",
    "    g = open(file, \"r\")\n",
    "    content = g.read()\n",
    "    f.write(content)\n",
    "    g.close()\n",
    "f.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89d240-af18-455f-bb83-1a29deeee246",
   "metadata": {},
   "source": [
    "#### Aside :Using crawl4ai to scrape web pages (writes content to /home/mort/crawl4ai.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05592e6a-c814-44de-83b9-d78259b0fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 scripts/testcrawler.py \"http://www.imm.dtu.dk/~alan/publications.html\" 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ef2f9-2ced-4769-a465-0948676ee37f",
   "metadata": {},
   "source": [
    "#### Note: The LlamaParse version of the text pdf (parsed from the web API: https://www.llamaindex.ai/llamaparse) was stored in /home/mort/crc5llamaparse. This version is used in what follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ac292-fa28-4fcb-a5dd-002b50a4fc6e",
   "metadata": {},
   "source": [
    "#### Code for preprocessing the RAG supplementary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ad0df7-ee8e-46e9-b238-2399293e17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def readtextfiles(path):\n",
    "    text_contents = {}\n",
    "    directory = os.path.join(path)\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "        \n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "        \n",
    "            text_contents[filename] = content\n",
    "        \n",
    "        return text_contents\n",
    "\n",
    "def chunksplitter(text, chunk_size=512, chunk_overlap=128):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,  # Desired chunk size in tokens\n",
    "        chunk_overlap=chunk_overlap,  # Overlap between chunks\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Split by paragraphs, then sentences, then words\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# use the nomic-embed-text model to calculate vector embeddings for all text chunks\n",
    "def getembedding(chunks):\n",
    "    embeds = ollama.embed(model=\"nomic-embed-text\", input=chunks)\n",
    "    return embeds.get('embeddings', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f159d-9e67-4f56-af9a-2627d26f042b",
   "metadata": {},
   "source": [
    "#### Add the supplementary text to a new database collection\n",
    "The embedded chunk vectors are always 768 bytes. Don't rerun unles using different chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c45bcb2-4e75-413c-83ca-2c36046d094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import numpy as np\n",
    "#chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5imagery/crc5rag\")\n",
    "chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5rag\")\n",
    "chromaclient.delete_collection(\"crc5rag\")\n",
    "collection = chromaclient.create_collection( name=\"crc5rag\", metadata={\"hnsw:space\": \"cosine\"} )\n",
    "\n",
    "# the RAG supplementary data, here using the llamaparse version of the main pdf\n",
    "textdocspath = \"/home/mort/crc5llamaparse\"\n",
    "text_data = readtextfiles(textdocspath)\n",
    "\n",
    "# read, break into chunks, embed and add to the chroma vector database \n",
    "for filename, text in text_data.items():\n",
    "    # default chunk size 512, overlap 128 \n",
    "    chunks = chunksplitter(text)\n",
    "    embeds = getembedding(chunks)\n",
    "    chunknumber = list(range(len(chunks)))\n",
    "    ids = [filename + str(index) for index in chunknumber]\n",
    "    metadatas = [{\"source\": filename} for index in chunknumber]\n",
    "    collection.add(ids=ids, documents=chunks, embeddings=embeds, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9451e-7588-4db5-a87a-d96ee9a152b5",
   "metadata": {},
   "source": [
    "#### Execute a query with a deepseek model and the supplementary text (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66a69bd-b4a6-4c28-91fc-f4b0ff5a1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ollama pull nomic-embed-text\n",
    "#!ollama pull deepseek-v3.1:671b-cloud\n",
    "!ollama pull deepseek-r1:14b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b667bab-86ee-46c4-90dc-a69234cc83ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        ID              SIZE      MODIFIED     \n",
      "nomic-embed-text:latest     0a109f422b47    274 MB    4 days ago      \n",
      "deepseek-r1:14b             c333b7232bdb    9.0 GB    4 days ago      \n",
      "deepseek-v3.1:671b-cloud    d3749919e45f    -         11 days ago     \n",
      "deepseek-r1:1.5b            e0979632db5a    1.1 GB    2 months ago    \n",
      "deepseek-r1:7b              755ced02ce7b    4.7 GB    2 months ago    \n",
      "gemma3:12b                  6fd036cefda5    8.1 GB    6 months ago    \n",
      "deepseek-r1:latest          0a8c26691023    4.7 GB    7 months ago    \n",
      "llama3.1:latest             46e0c10c039e    4.9 GB    8 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807bd52a-fa9b-435e-80a0-95c6c5560909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7503\n",
      "mixture model (the feed-forward neural network or FFN). In the case of the\n",
      "neural network, the back propagation      training algorithm is by far the most\n",
      "commonly used. We make some considerable eﬀort to explain it in detail and,\n",
      "in Appendix B, to develop more sophisticated and eﬃcient analytical methods\n",
      "based on scaled conjugate gradient and the Kalman ﬁlter. All of these, how-\n",
      "ever, will be seen to become unwieldy for so-called deep learning or multiple\n",
      "\n",
      "---\n",
      "B\n",
      "Neural Network Training Algorithms\n",
      "The gradient descent back-propagation algorithm introduced in Chapter 6 is\n",
      "notoriously slow to converge. In this appendix, we will develop two additional\n",
      "training algorithms for the two-layer, feed-forward neural network of Figure\n",
      "6.11. The ﬁrst of these, the scaled conjugate gradient, makes use of the second\n",
      "derivatives of the cost function with respect to the synaptic weights, i.e., of\n",
      "the Hessian matrix. The second, the extended Kalman ﬁlter method, takes\n",
      "\n",
      "Neural networks                                                         257\n",
      "            6.5.3    Back propagation\n",
      "            A minimum of the cost function, Equation (6.33), can be found with various\n",
      "            search algorithms, whereby back propagation is certainly the most well-known\n",
      "            and extensively used method. Modern neural network libraries like Tensor-\n",
      "            Flow/Keras or PyTorch implement back propagation very eﬃciently with so-\n",
      "\n",
      "Finally, with Equation (6.40), we obtain the update rule for step 4 of the\n",
      "back propagation algorithm:\n",
      "                   Wh(ν + 1) = W h(ν) + η g(ν)δh(ν)⊤.                         (6.43)\n",
      "---\n",
      "Neural networks                                                                                  261\n",
      "Listing 6.4: A class for a feed-forward neural network trained with back prop-\n",
      "agation (excerpt from the Python module auxil.supervisedclass.py).\n",
      " 1 c l a s s Ffnbp ( Ffn ):\n",
      "\n",
      "ent algorithm.\n",
      "---\n",
      "474                                   Neural Network Training Algorithms\n",
      "B.3    Extended Kalman ﬁlter training\n",
      "                    In this section the recursive linear regression method described in Appendix\n",
      "                      A will be applied to train the feed-forward neural network of Figure 6.10.\n",
      "                  The appropriate cost function in this case is the quadratic function, Equation\n",
      "(6.30), or more speciﬁcally, its local version\n",
      "\n",
      "allows them to model posterior probabilities of class membership.\n",
      "     The Python object class Ffn, an excerpt of which is given in Listing 6.3,\n",
      "mirrors the network architecture of Figure 6.10. It will form the basis for the\n",
      "implementation of the back propagation training algorithm developed below\n",
      "and also for the more eﬃcient training algorithms described in Appendix B.\n",
      "6.5.2    Cost functions\n",
      "\n",
      "ensemble of neural network classiﬁers. For other examples of adaptive boost-\n",
      "ing of neural networks, see Schwenk and Bengio (2000) and Murphey et al.\n",
      "(2001).\n",
      "  In order to motivate the adaptive boosting idea, consider the training of\n",
      "the feed-forward neural network classiﬁer of Chapter 6 when there are just\n",
      "two classes to choose between. Making use of stochastic training, we train the\n",
      "network by minimizing the local cost function, Equation (6.34), on randomly\n",
      "\n",
      "Under certain assumptions about the distribution of the training data, the\n",
      "quadratic cost function\n",
      "                                      m\n",
      "                       E(Wh, Wo) = 1 ∑ ‖ℓ(ν) − m(ν)‖2                 (6.30)\n",
      "                                   2 ν=1\n",
      "can be justiﬁed as a training criterion for feed-forward networks (Exercise 4).\n",
      "The network weights Wh and W o must be adjusted so as to minimize E .\n",
      "This minimization will clearly tend to make the network produce the output\n",
      "signal\n",
      "\n",
      "return                                                                                                            35                                   # v ^ T . H     np . hstack (( REo , REh ))\n",
      "B.2   Scaled conjugate gradient training\n",
      "The back-propagation algorithm of Chapter 6 attempts to minimize the cost\n",
      "function   locally, that is, weight updates are made immediately after presen-\n",
      "tation of a single training pair to the network. We will now consider a global\n",
      "\n",
      "for designing support vector machines (Belousov et al., 2002), as we will see\n",
      "later.\n",
      "                Accordingly, we shall develop a classiﬁer based on the two-layer, feed-\n",
      "forward architecture∗ shown in Figure 6.11. For the             νth training pixel, the\n",
      "  ∗The adjective feed-forward merely serves to diﬀerentiate this network structure from\n",
      "other networks having feedback connections.\n",
      "---\n",
      "  Neural networks                                                        253\n",
      "\n",
      "Since each of the Nc factors is positive, the upper bound will be minimized\n",
      "when           d  ⌈ 1 − (1 − βi)(1 − ϵi)⌉\n",
      "              dβi           √βi           = 0,  i = 1. . . Nc,\n",
      "with solution                  βi = 1 ϵi  .\n",
      "                                      − ϵi\n",
      "Substituting this back into Equation (A.23) gives the upper bound Equation\n",
      "(7.26) and the proof is complete.\n",
      "---\n",
      "B\n",
      "Neural Network Training Algorithms\n",
      "The gradient descent back-propagation algorithm introduced in Chapter 6 is\n",
      "\n",
      "⒱⒰         ⒱⒰           ⒱⒰\n",
      "                         Hidden layer       Output layer\n",
      "FIGURΕ 6.11\n",
      "A two-layer feed-forward neural network with L hidden neurons for classi-\n",
      "ﬁcation of N-dimensional data into K classes. The argument ν                identiﬁes a\n",
      "training example.\n",
      "6.5.1  The neural network classiﬁer\n",
      "Single-layer networks turn out to be rather limited in the kind of classiﬁ-\n",
      "cation tasks that they can handle. In fact, only so-called           linearly separable\n",
      "\n",
      "This also makes the fact that 1 − n0(ν) = 0 explicit. Equation (6.42) is the\n",
      "origin of the term “back propagation,” since it propagates the negative rate\n",
      "of change of the cost function with respect to the output activations  δo(ν)\n",
      "backwards through the network to determine the negative rate of change with\n",
      "respect to the hidden activations δh(ν).\n",
      "  Finally, with Equation (6.40), we obtain the update rule for step 4 of the\n",
      "back propagation algorithm:\n",
      "\n",
      "network by minimizing the local cost function, Equation (6.34), on randomly\n",
      "selected labeled examples. To begin with the training data are sampled uni-\n",
      "formly, as is done, for example, in the back propagation training algorithm\n",
      "of Listing 6.4. We can represent such a sampling scheme with the uniform,\n",
      "discrete probability distribution\n",
      "                        p1(ν) = 1/m,    ν = 1 . . . m,\n",
      "over the m training examples. Let U1 be the set of incorrectly classiﬁed exam-\n",
      "\n",
      "FIGURΕ 6.12\n",
      "Local cross entropy as a function of training epoch for gradient descent back\n",
      "propagation.\n",
      "---\n",
      "           Neural networks                                                      263\n",
      "           (minimizing the local cost function Equation (6.34)) relative to the much more\n",
      "           eﬃcient scaled conjugate gradient training algorithm described in Appendix\n",
      "           B can be seen in a direct comparison. First with the ﬂag -a set to 3 for\n",
      "\n",
      "of neural networks in so many aspects of data analysis in the last few years.\n",
      "       The classic feed forward network was always given prominence in the dis-\n",
      "       cussion of supervised image classiﬁcation in the earlier editions, but to move\n",
      "       with the times I’ve taken the opportunity to extend the treatment to include\n",
      "       convolutional networks for supervised transfer learning and segmentation of\n",
      "       remote sensing image data. The examples are programmed in the latest Ten-\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import html\n",
    "import ollama\n",
    "import chromadb\n",
    "\n",
    "# Initialize ChromaDB client and collection\n",
    "#chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5imagery/crc5rag\")\n",
    "chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5rag\")\n",
    "collection = chromaclient.get_collection(name=\"crc5rag\")\n",
    "\n",
    "def ragask(query):\n",
    "    # Embed the query\n",
    "    queryembed = ollama.embed(model=\"nomic-embed-text\", input=query)['embeddings']\n",
    "    # Retrieve related documents (16 chunks)\n",
    "    relateddocs = '\\n\\n'.join(collection.query(query_embeddings=queryembed, n_results=16)['documents'][0])\n",
    "\n",
    "    # view chunked related docs\n",
    "    print(len(relateddocs))\n",
    "    print(relateddocs)\n",
    "    \n",
    "    # Generate a response\n",
    "    prompt = f\"Answer the question: {query} referring to the following text as a resource: {relateddocs}\"\n",
    "    # using deepseek-r1:14b\n",
    "    response = ollama.generate(model=\"deepseek-r1:14b\", prompt=prompt, stream=False, think=False)['response']   \n",
    "    # Ensure the response is valid Markdown\n",
    "    return html.escape(response)\n",
    "\n",
    "# Launch Gradio Interface (ChatInterface not appropriate for RAG application!)\n",
    "gr.Interface(fn=ragask,inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
    "             outputs=\"markdown\",\n",
    "             description=\"Ask questions about the book contents\",\n",
    "             title=\"Image Analysis, Classification and Change Detection in Remote Sensing\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155124d-17bd-47dd-85cb-7ff45a7b54b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
