{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d749a561-c8fc-4991-afe9-7113d3c6017c",
   "metadata": {},
   "source": [
    "### Trying out RAG with ollama and chromadb\n",
    "ollama is installed in the python environment venvcrc5 from where this notebook is started.\n",
    "\n",
    "ollama is recommended over hugging face for local experimentation\n",
    "\n",
    "it uses a docker-like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de73eae-777f-4b14-9ed4-cbdd2cfd4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama version is 0.5.7\n",
      "NAME                       ID              SIZE      MODIFIED     \n",
      "deepseek-r1:latest         0a8c26691023    4.7 GB    19 hours ago    \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    19 hours ago    \n",
      "llama3.1:latest            46e0c10c039e    4.9 GB    11 days ago     \n"
     ]
    }
   ],
   "source": [
    "!ollama --version\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d32e73-ede0-4a86-b35a-7fa55ebf7cfb",
   "metadata": {},
   "source": [
    "#### The pdfreader translates any pdf document to text readable by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59742336-ba28-4ad4-ad9f-b483638d3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "# my textbook, 5th ed\n",
    "reader = PdfReader(\"/home/mort/LaTeX/new projects/CRC5/main.pdf\")\n",
    "total_pages = len(reader.pages)\n",
    "all_text = \"\"\n",
    "for page_num in range(total_pages):\n",
    "    page = reader.pages[page_num]\n",
    "    all_text += page.extract_text()\n",
    "f = open(\"/home/mort/temp/main.txt\", \"w\")\n",
    "f.write(all_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a22089-22a2-4f18-aa53-8c8bc911f7f0",
   "metadata": {},
   "source": [
    "#### Here the original LaTeX files are collected instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d7d2e14-d5c0-4b02-8151-7a63f0031b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# Find `.tex` files in LaTeX directory and all subdirectories\n",
    "tex_files = glob.glob('/home/mort/LaTeX/new projects/CRC5/**/chapter[1-9].tex', recursive = True)\n",
    "tex_files.sort()\n",
    "f = open(\"/home/mort/temp/main.txt\", \"w\")\n",
    "for file in tex_files:\n",
    "    g = open(file, \"r\")\n",
    "    content = g.read()\n",
    "    f.write(content)\n",
    "    g.close()\n",
    "f.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ac292-fa28-4fcb-a5dd-002b50a4fc6e",
   "metadata": {},
   "source": [
    "#### Code for preprocessing the RAG supplementary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ad0df7-ee8e-46e9-b238-2399293e17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def readtextfiles(path):\n",
    "    text_contents = {}\n",
    "    directory = os.path.join(path)\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "        \n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "        \n",
    "            text_contents[filename] = content\n",
    "        \n",
    "        return text_contents\n",
    "\n",
    "def chunksplitter(text, chunk_size=256, chunk_overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,  # Desired chunk size in characters or tokens\n",
    "        chunk_overlap=chunk_overlap,  # Overlap between chunks\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Split by paragraphs, then sentences, then words\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# use the nomic-embed-text model to calculate vector embeddings for all text chunks\n",
    "def getembedding(chunks):\n",
    "    embeds = ollama.embed(model=\"nomic-embed-text\", input=chunks)\n",
    "    return embeds.get('embeddings', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f159d-9e67-4f56-af9a-2627d26f042b",
   "metadata": {},
   "source": [
    "#### Add the supplementary text to a new database collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c45bcb2-4e75-413c-83ca-2c36046d094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5imagery/crc5rag\")\n",
    "chromaclient.delete_collection(\"crc5rag\")\n",
    "collection = chromaclient.create_collection(name=\"crc5rag\", metadata={\"hnsw:space\": \"cosine\"}  )\n",
    "\n",
    "# the RAG supplementary data\n",
    "textdocspath = \"/home/mort/temp\"\n",
    "text_data = readtextfiles(textdocspath)\n",
    "\n",
    "# read, break into chunks, embed and add to the chroma vector database \n",
    "for filename, text in text_data.items():\n",
    "    # chunk size set 256, overlap 50 (defaults)\n",
    "    chunks = chunksplitter(text,1000,100)\n",
    "    embeds = getembedding(chunks)\n",
    "    chunknumber = list(range(len(chunks)))\n",
    "    ids = [filename + str(index) for index in chunknumber]\n",
    "    metadatas = [{\"source\": filename} for index in chunknumber]\n",
    "    collection.add(ids=ids, documents=chunks, embeddings=embeds, metadatas=metadatas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9451e-7588-4db5-a87a-d96ee9a152b5",
   "metadata": {},
   "source": [
    "#### Execute a query with llama3.1 or deepseek-r1 and the supplementary text (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66a69bd-b4a6-4c28-91fc-f4b0ff5a1ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n",
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 96c415656d37... 100% ▕████████████████▏ 4.7 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling 40fb844194b2... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "!ollama pull nomic-embed-text\n",
    "#!ollama pull llama3.1\n",
    "!ollama pull deepseek-r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae915395-e150-4f91-b2b3-4cfbcd55ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import html\n",
    "import ollama\n",
    "import chromadb\n",
    "\n",
    "# Initialize ChromaDB client and collection\n",
    "chromaclient = chromadb.PersistentClient(path=\"/home/mort/crc5imagery/crc5rag\")\n",
    "collection = chromaclient.get_collection(name=\"crc5rag\")\n",
    "\n",
    "def ragask(query):\n",
    "    # Embed the query\n",
    "    queryembed = ollama.embed(model=\"nomic-embed-text\", input=query)['embeddings']\n",
    "    # Retrieve related documents\n",
    "    relateddocs = '\\n\\n'.join(collection.query(query_embeddings=queryembed, n_results=3)['documents'][0])\n",
    "    # Generate a response\n",
    "    prompt = f\"Answer the question: {query}, referring to the following text as a resource: {relateddocs}\"\n",
    "    response = ollama.generate(model=\"deepseek-r1\", prompt=prompt, stream=False)['response']   \n",
    "    # Ensure the response is valid Markdown\n",
    "    return html.escape(response)\n",
    "\n",
    "# Launch Gradio Interface (ChatInterface not appropriate for RAG application!)\n",
    "gr.Interface(fn=ragask,inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
    "             outputs=\"markdown\",\n",
    "             description=\"Ask questions about the book contents\",\n",
    "             title=\"Image Analysis, Classification and Change Detection in Remote Sensing\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28301ed-5c45-4b54-987b-ad1c37799da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
